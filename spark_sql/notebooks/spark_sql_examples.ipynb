{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark SQL\n",
    "\n",
    "Before you begin, make sure that you've installed spark of version `2.3` or higher (see `README.md`)\n",
    "\n",
    "**Links**\n",
    "\n",
    "* https://spark.apache.org/docs/latest/sql-getting-started.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:38:34.560581Z",
     "start_time": "2020-02-12T00:38:34.274519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/spark_sql/notebooks\r\n",
      "-rwxr-xr-x 1 root root 1.2K Feb  3 20:03 README.md\r\n"
     ]
    }
   ],
   "source": [
    "!pwd && ls -lah | grep README"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запуск spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:38:40.467741Z",
     "start_time": "2020-02-12T00:38:37.096692Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyspark\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"spark_sql_examples\") \\\n",
    "    .config(\"spark.executor.memory\", \"10g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:38:41.219153Z",
     "start_time": "2020-02-12T00:38:40.469422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\r\n",
      "      ____              __\r\n",
      "     / __/__  ___ _____/ /__\r\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\r\n",
      "   /___/ .__/\\_,_/_/ /_/\\_\\   version 2.4.4\r\n",
      "      /_/\r\n",
      "                        \r\n",
      "Using Scala version 2.11.12, OpenJDK 64-Bit Server VM, 1.8.0_242\r\n",
      "Branch \r\n",
      "Compiled by user  on 2019-08-27T21:31:02Z\r\n",
      "Revision \r\n",
      "Url \r\n",
      "Type --help for more information.\r\n"
     ]
    }
   ],
   "source": [
    "! spark-submit --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:38:42.642406Z",
     "start_time": "2020-02-12T00:38:42.639115Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '/workspace/data/ml-25m'\n",
    "\n",
    "RATINGS_PATH = os.path.join(DATA_PATH, 'ratings.csv')\n",
    "MOVIES_PATH = os.path.join(DATA_PATH, 'movies.csv')\n",
    "TAGS_PATH = os.path.join(DATA_PATH, 'tags.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## DataFrame creation\n",
    "\n",
    "DataFrame можно создать несколькими способами:\n",
    "\n",
    "* из файла\n",
    "* из существующего RDD\n",
    "* из другого DataFrame'a\n",
    "\n",
    "### From file\n",
    "\n",
    "В случае с созданием из csv файла, может понадобится указать схему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:38:44.546356Z",
     "start_time": "2020-02-12T00:38:43.547866Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('user_id', IntegerType()),\n",
    "    StructField('movie_id', IntegerType()),\n",
    "    StructField('rating', FloatType()),\n",
    "    StructField('timestamp', IntegerType())\n",
    "])\n",
    "\n",
    "ratings_df = sqlContext.read \\\n",
    "    .format('com.databricks.spark.csv') \\\n",
    "    .schema(schema) \\\n",
    "    .options(header='true', delimiter=',') \\\n",
    "    .load('file:///' + RATINGS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:38:44.564537Z",
     "start_time": "2020-02-12T00:38:44.548067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:38:45.606790Z",
     "start_time": "2020-02-12T00:38:44.566569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id=1, movie_id=296, rating=5.0, timestamp=1147880044),\n",
       " Row(user_id=1, movie_id=306, rating=3.5, timestamp=1147868817),\n",
       " Row(user_id=1, movie_id=307, rating=5.0, timestamp=1147868828),\n",
       " Row(user_id=1, movie_id=665, rating=5.0, timestamp=1147878820),\n",
       " Row(user_id=1, movie_id=899, rating=3.5, timestamp=1147868510)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From RDD\n",
    "\n",
    "Для того чтобы построить DataFrame из RDD нужно у RDD вызвать метод `toDF`.\n",
    "\n",
    "*Remark:* RDD можно получить из DataFrame с помощью аттрибута `rdd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:38:45.642157Z",
     "start_time": "2020-02-12T00:38:45.608464Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings = sc.textFile('file:///' + RATINGS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:38:46.082054Z",
     "start_time": "2020-02-12T00:38:45.662712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['userId,movieId,rating,timestamp',\n",
       " '1,296,5.0,1147880044',\n",
       " '1,306,3.5,1147868817',\n",
       " '1,307,5.0,1147868828',\n",
       " '1,665,5.0,1147878820']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:38:48.415098Z",
     "start_time": "2020-02-12T00:38:48.347079Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "ratings_df = ratings \\\n",
    "    .map(lambda s: s.split(',')) \\\n",
    "    .filter(lambda arr: arr[0].isdigit()) \\\n",
    "    .map(lambda arr: Row(user_id=int(arr[0]), \n",
    "                         movie_id=int(arr[1]), \n",
    "                         rating=float(arr[2]), \n",
    "                         timestamp=int(arr[3])))\\\n",
    "    .toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:38:48.562327Z",
     "start_time": "2020-02-12T00:38:48.558932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movie_id: long (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## DataFrame API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:38:49.595760Z",
     "start_time": "2020-02-12T00:38:48.974527Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "movies_df = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load('file:///' + MOVIES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:38:49.601173Z",
     "start_time": "2020-02-12T00:38:49.597651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильмы с наибольшим средним рейтингом\n",
    "\n",
    "Найти 10 фильмов с наибольшим средним рейтингом. Вывести их названия и средний рейтинг.\n",
    "\n",
    "Сравните код ниже с кодом, использующим RDD API (см. `apache_spark/notebooks/spark_examples.ipynb`):\n",
    "\n",
    "```\n",
    "ratings \\\n",
    "    .map(lambda r: (r.movie_id, (r.rating, 1))) \\\n",
    "    .reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1])) \\\n",
    "    .mapValues(lambda ratings: ratings[0] / ratings[1]) \\\n",
    "    .join(movies) \\\n",
    "    .sortBy(lambda key_value: key_value[1][0], ascending=False) \\\n",
    "    .take(10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df \\\n",
    "    .groupby('movie_id') \\\n",
    "    .agg(F.mean('rating').alias('mean_rating'), \n",
    "         F.count('rating').alias('ratings_count')) \\\n",
    "    .join(movies_df, ratings_df['movie_id'] == movies_df['movieId'], how='inner') \\\n",
    "    .sort(F.col('mean_rating').desc()) \\\n",
    "    .take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильмы с наибольшим числом оценок\n",
    "\n",
    "Найти 10 фильмов с наибольшим числом оценок. Вывести их названия и число оценок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_frequency_pdf = ratings_df \\\n",
    "    .groupby('movie_id') \\\n",
    "    .count() \\\n",
    "    .join(movies_df, ratings_df['movie_id'] == movies_df['movieId']) \\\n",
    "    .sort(F.col('count').desc()) \\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_frequency_pdf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.createTempView('ratings')\n",
    "movies_df.createTempView('movies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT movie_id, COUNT(*), first(title) as title\n",
    "    FROM ratings INNER JOIN movies ON ratings.movie_id == movies.movieId\n",
    "    WHERE movies.title LIKE '%(1994)%'\n",
    "    GROUP BY movie_id\n",
    "    ORDER BY COUNT(*) DESC\n",
    "\"\"\"\n",
    "\n",
    "movies_frequency = spark.sql(query)\n",
    "movies_frequency.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spark.sql(query).explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## User Defined Function (UDF)\n",
    "\n",
    "\n",
    "### Количество вышедших фильмов по годам\n",
    "\n",
    "Мы знаем, что название фильма содержит информацию о дате выхода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_release_year(title):\n",
    "    result = re.match(r'.*(\\(\\d+\\))', title)\n",
    "    return int(result.group(1)[1:-1]) if result is not None else None\n",
    "\n",
    "\n",
    "get_release_year_udf = F.udf(get_release_year, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relase_count_by_year = movies_df \\\n",
    "    .withColumn('year', get_release_year_udf('title')) \\\n",
    "    .filter((F.col('year').isNotNull()) & (F.col('year') < 2025)) \\\n",
    "    .groupby('year') \\\n",
    "    .count() \\\n",
    "    .sort(F.col('year')) \\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relase_count_by_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "relase_count_by_year.set_index('year')['count'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Window Functions\n",
    "\n",
    "Хотим понять, сколько времени проходит между последовательными оценками для пользователей, более формально:\n",
    "\n",
    "Для пользователя $u$ есть последовательность $(m_1, r_1, t_1), \\ldots, (m_n, r_n, t_n)$, где $t_i \\leq t_{i+1}$. Рассмотрим последовательность $\\Delta_i = t_{i+1} - t_i$, для $i=1,\\ldots,n-1$.\n",
    "\n",
    "Хотим построить распределение величины $\\Delta_i$ используя информацию обо всех пользователях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:46:37.603871Z",
     "start_time": "2020-02-12T00:46:37.310006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id=964, movie_id=1641, rating=5.0, timestamp=898993065, next_timestamp=898993065),\n",
       " Row(user_id=964, movie_id=1704, rating=4.0, timestamp=898993065, next_timestamp=898993065),\n",
       " Row(user_id=964, movie_id=1721, rating=3.0, timestamp=898993065, next_timestamp=898993197),\n",
       " Row(user_id=964, movie_id=1639, rating=3.0, timestamp=898993197, next_timestamp=898993197),\n",
       " Row(user_id=964, movie_id=1653, rating=5.0, timestamp=898993197, next_timestamp=898993197),\n",
       " Row(user_id=964, movie_id=1727, rating=4.0, timestamp=898993197, next_timestamp=898993275),\n",
       " Row(user_id=964, movie_id=1682, rating=4.0, timestamp=898993275, next_timestamp=898993275),\n",
       " Row(user_id=964, movie_id=2801, rating=5.0, timestamp=898993275, next_timestamp=898993309),\n",
       " Row(user_id=964, movie_id=1057, rating=4.0, timestamp=898993309, next_timestamp=898993310),\n",
       " Row(user_id=964, movie_id=1407, rating=4.0, timestamp=898993310, next_timestamp=898993337)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "user_window = Window.orderBy('timestamp').partitionBy('user_id')\n",
    "\n",
    "ratings_df \\\n",
    "    .withColumn('next_timestamp', F.lead('timestamp').over(user_window)) \\\n",
    "    .filter(F.col('next_timestamp').isNotNull()) \\\n",
    "    .take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY = 24 * 60 * 60\n",
    "\n",
    "ratings_df \\\n",
    "    .withColumn('next_timestamp', F.lead('timestamp').over(user_window)) \\\n",
    "    .filter(F.col('next_timestamp').isNotNull()) \\\n",
    "    .withColumn('delta', (F.col('next_timestamp') - F.col('timestamp')) / F.lit(DAY)) \\\n",
    "    .select('delta') \\\n",
    "    .filter(F.col('delta') <= 365) \\\n",
    "    .sample(False, 0.1) \\\n",
    "    .toPandas().plot.hist(bins=100, logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Упражнения. Recommender System\n",
    "\n",
    "Пусть $U$ - множество пользователей, $I$ - множество фильмов, и $R = (r_{ui})$ - матрица рейтингов. \n",
    "\n",
    "Через $R_u$ будем обозначать строку матрицы $R$, соотвествующую пользователю $u$.\n",
    "\n",
    "## Most similar items\n",
    "\n",
    "Для каждого фильма $i$ определим множество $U(i) = \\{ u \\in U \\mid r_{ui} \\neq 0 \\}$ - множество пользователей, поставивших фильму $i$ оценку.\n",
    "\n",
    "Тогда мы можем определить множество $I(i) = \\left\\{ i' \\in I ~\\Big|~ sim(i, i') = \\frac{|U(i) ~\\cap~ U(i')|}{|U(i) ~\\cup~ U(i')|} > \\delta \\right\\}$ - множество похожих фильмов.\n",
    "\n",
    "Можно отсортировать элементы множества $I(i)$ по неубыванию $sim(i, i')$.\n",
    "\n",
    "Реализуйте функцию, которая на вход получает `movie_id` и возвращает топ `N` фильмов отранжированных по $sim$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "выберем произвольных 10к пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:38:58.237458Z",
     "start_time": "2020-02-12T00:38:58.218945Z"
    }
   },
   "outputs": [],
   "source": [
    "n_users = 10000\n",
    "selected_users = ratings_df \\\n",
    "    .select('user_id') \\\n",
    "    .distinct() \\\n",
    "    .sample(False, 0.01) \\\n",
    "    .limit(n_users)\n",
    "# from here: https://stackoverflow.com/a/32837900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:38:58.494190Z",
     "start_time": "2020-02-12T00:38:58.474870Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings_df = ratings_df \\\n",
    "    .join(selected_users, 'user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:40:49.028797Z",
     "start_time": "2020-02-12T00:39:02.311718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261425"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.persist()\n",
    "ratings_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:40:49.035419Z",
     "start_time": "2020-02-12T00:40:49.030594Z"
    }
   },
   "outputs": [],
   "source": [
    "movies_df = movies_df.withColumnRenamed(\"movieId\", \"movie_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:40:49.110945Z",
     "start_time": "2020-02-12T00:40:49.037366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                    title  \\\n",
       "0         1         Toy Story (1995)   \n",
       "1         2           Jumanji (1995)   \n",
       "2         3  Grumpier Old Men (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:40:49.118684Z",
     "start_time": "2020-02-12T00:40:49.112583Z"
    }
   },
   "outputs": [],
   "source": [
    "def sim_films(ratings_df, movies_df, movie_id, N=10):\n",
    "    movie_reviewers = ratings_df \\\n",
    "        .filter(F.col('movie_id') == movie_id) \\\n",
    "        .select(\"user_id\")    \n",
    "    movie_reviewers_count = movie_reviewers.count()\n",
    "    \n",
    "    intersections = ratings_df \\\n",
    "        .join(movie_reviewers, 'user_id') \\\n",
    "        .groupby('movie_id') \\\n",
    "        .count() \\\n",
    "        .withColumnRenamed('count', 'intersection')\n",
    "    \n",
    "    movie_count = ratings_df \\\n",
    "        .groupby('movie_id') \\\n",
    "        .count()\n",
    "    \n",
    "    result = intersections \\\n",
    "      .join(movie_count, 'movie_id')\n",
    "    \n",
    "    sim = result \\\n",
    "        .withColumn('sim', result['intersection'] / (movie_reviewers_count + result['count'] - result['intersection'])) \\\n",
    "        .sort(F.col('sim').desc()) \\\n",
    "        .select('movie_id', 'sim') \\\n",
    "        .limit(N) \\\n",
    "        .join(movies_df, \"movie_id\") \\\n",
    "        .sort(F.col('sim').desc())\n",
    "    \n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:41:36.843113Z",
     "start_time": "2020-02-12T00:41:36.607779Z"
    }
   },
   "outputs": [],
   "source": [
    "sim = sim_films(ratings_df, movies_df, 356)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:41:38.527936Z",
     "start_time": "2020-02-12T00:41:36.844734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>sim</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Forrest Gump (1994)</td>\n",
       "      <td>Comedy|Drama|Romance|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>480</td>\n",
       "      <td>0.534010</td>\n",
       "      <td>Jurassic Park (1993)</td>\n",
       "      <td>Action|Adventure|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>296</td>\n",
       "      <td>0.519177</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "      <td>Comedy|Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>318</td>\n",
       "      <td>0.499094</td>\n",
       "      <td>Shawshank Redemption, The (1994)</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>0.489202</td>\n",
       "      <td>Silence of the Lambs, The (1991)</td>\n",
       "      <td>Crime|Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>110</td>\n",
       "      <td>0.471679</td>\n",
       "      <td>Braveheart (1995)</td>\n",
       "      <td>Action|Drama|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>589</td>\n",
       "      <td>0.469806</td>\n",
       "      <td>Terminator 2: Judgment Day (1991)</td>\n",
       "      <td>Action|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>527</td>\n",
       "      <td>0.447475</td>\n",
       "      <td>Schindler's List (1993)</td>\n",
       "      <td>Drama|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2571</td>\n",
       "      <td>0.435514</td>\n",
       "      <td>Matrix, The (1999)</td>\n",
       "      <td>Action|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>150</td>\n",
       "      <td>0.433298</td>\n",
       "      <td>Apollo 13 (1995)</td>\n",
       "      <td>Adventure|Drama|IMAX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id       sim                              title  \\\n",
       "0       356  1.000000                Forrest Gump (1994)   \n",
       "1       480  0.534010               Jurassic Park (1993)   \n",
       "2       296  0.519177                Pulp Fiction (1994)   \n",
       "3       318  0.499094   Shawshank Redemption, The (1994)   \n",
       "4       593  0.489202   Silence of the Lambs, The (1991)   \n",
       "5       110  0.471679                  Braveheart (1995)   \n",
       "6       589  0.469806  Terminator 2: Judgment Day (1991)   \n",
       "7       527  0.447475            Schindler's List (1993)   \n",
       "8      2571  0.435514                 Matrix, The (1999)   \n",
       "9       150  0.433298                   Apollo 13 (1995)   \n",
       "\n",
       "                             genres  \n",
       "0          Comedy|Drama|Romance|War  \n",
       "1  Action|Adventure|Sci-Fi|Thriller  \n",
       "2       Comedy|Crime|Drama|Thriller  \n",
       "3                       Crime|Drama  \n",
       "4             Crime|Horror|Thriller  \n",
       "5                  Action|Drama|War  \n",
       "6                     Action|Sci-Fi  \n",
       "7                         Drama|War  \n",
       "8            Action|Sci-Fi|Thriller  \n",
       "9              Adventure|Drama|IMAX  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим несколько вариантов простой Рекомендательной Системы.\n",
    "\n",
    "*Основная цель:* порекомендовать фильм пользователю. (Для простоты опустим информацию о самих рейтингах)\n",
    "\n",
    "## Methods\n",
    "\n",
    "При разработке сложных методов, сначала нужно выбрать несколько простотых методов (`Baseline`), относительно которых мы будем сравнивать новый метод.\n",
    "\n",
    "### POP\n",
    "\n",
    "Будем всегда рекомендовать самые популярные фильмы (с наибольшим цислом оценок пользователей).\n",
    "\n",
    "Не смотря на свою простоту, в ряде задач показывает себя достаточно хорошо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:41:40.861086Z",
     "start_time": "2020-02-12T00:41:40.858705Z"
    }
   },
   "outputs": [],
   "source": [
    "import abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:41:41.069773Z",
     "start_time": "2020-02-12T00:41:41.066722Z"
    }
   },
   "outputs": [],
   "source": [
    "class Recommender(metaclass=abc.ABCMeta):\n",
    "    @abc.abstractmethod\n",
    "    def recommend(self, users): raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T06:18:30.372141Z",
     "start_time": "2020-02-12T06:18:30.367112Z"
    }
   },
   "outputs": [],
   "source": [
    "class Popular(Recommender):\n",
    "    def __init__(self, ratings_df, N=10):\n",
    "        self.N = N\n",
    "        self.pop = ratings_df \\\n",
    "                    .groupby('movie_id') \\\n",
    "                    .count() \\\n",
    "                    .sort(F.col('count').desc()) \\\n",
    "                    .limit(N) \\\n",
    "                    .select('movie_id') \\\n",
    "                    .withColumn(\"rank\", F.monotonically_increasing_id()) \\\n",
    "                    .persist()\n",
    "    \n",
    "    def recommend(self, users):\n",
    "        # TODO: возможно, стоит учитывать какие фильмы уже посмотрел пользователь\n",
    "        return users \\\n",
    "                .crossJoin(self.pop) \\\n",
    "                .sort(F.col('user_id'), F.col('rank'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T06:18:38.825380Z",
     "start_time": "2020-02-12T06:18:38.796099Z"
    }
   },
   "outputs": [],
   "source": [
    "p = Popular(ratings_df, N=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T06:19:31.929039Z",
     "start_time": "2020-02-12T06:18:40.425125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>287</td>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>287</td>\n",
       "      <td>318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>287</td>\n",
       "      <td>296</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>287</td>\n",
       "      <td>593</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>964</td>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>964</td>\n",
       "      <td>318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>964</td>\n",
       "      <td>296</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>964</td>\n",
       "      <td>593</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1636</td>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1636</td>\n",
       "      <td>318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rank\n",
       "0      287       356     0\n",
       "1      287       318     1\n",
       "2      287       296     2\n",
       "3      287       593     3\n",
       "4      964       356     0\n",
       "5      964       318     1\n",
       "6      964       296     2\n",
       "7      964       593     3\n",
       "8     1636       356     0\n",
       "9     1636       318     1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.recommend(selected_users.limit(100)).limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-based Collaborative Filtering\n",
    "\n",
    "1. Для пользователя $u$ определим множество похожих пользователей как \n",
    "\n",
    "$$U(u) = \\left\\{ u' \\in U \\mid sim(u, u') > \\alpha \\right\\},$$\n",
    "\n",
    "где $sim(u, u')$ — одна из возможных мер близости $u'$ к $u$, например, косинусная близость между $R_{u}$ и $R_{u'}$\n",
    "\n",
    "2. $$I(u) = \\left\\{ i \\in I ~\\Big|~ B(i) = \\frac{|U(u) ~\\cap~ U(i)|}{|U(u) ~\\cup~ U(i)|} > 0 \\right\\}$$\n",
    "\n",
    "\n",
    "3. Отсортировать $i \\in I(u)$ по убыванию $B(i)$, взять top $N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T06:08:50.419647Z",
     "start_time": "2020-02-12T06:08:50.416582Z"
    }
   },
   "outputs": [],
   "source": [
    "class UCF(Recommender):\n",
    "    def __init__(self, ratings_df):\n",
    "        self.pop = ratings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item-kNN\n",
    "\n",
    "1. Для пользователя $u$ мы знаем $R(u) = \\{ i \\in I \\mid r_{ui} \\neq 0 \\} $\n",
    "\n",
    "\n",
    "2. Для каждого $i \\in R(u)$ построим $I(i)$ - множество похожих фильмов\n",
    "\n",
    "\n",
    "3. Отсортируем элементы множества $ \\bigcup_{i \\in R(u)} I(i) $, возьмем top $N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "######### YOUR CODE HERE #############\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Protocol\n",
    "\n",
    "Теперь опишем, как будем оценивать качество рассматриваемых методов.\n",
    "\n",
    "### Data Splits\n",
    "\n",
    "Так как в данных `ratings` есть поле `timestamp`, то для каждого пользователя отсортируем его рейтинги по времени и первые $80\\%$ рейтингов отнесем в `Train`, еще $10\\%$ в `Validation`, и остальное в `Test`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:46:43.214666Z",
     "start_time": "2020-02-12T00:46:43.209388Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_val_test_split(df, train_size=0.8, valid_size=0.1):\n",
    "    # https://stackoverflow.com/a/51773836\n",
    "    user_window = Window.orderBy('timestamp').partitionBy('user_id')\n",
    "    \n",
    "    df_with_ranks = df \\\n",
    "      .withColumn('rank', F.percent_rank().over(user_window))\n",
    "\n",
    "    train = df_with_ranks \\\n",
    "      .filter(df_with_ranks['rank'] < train_size) \\\n",
    "      .drop('rank')\n",
    "\n",
    "    valid = df_with_ranks \\\n",
    "      .filter((train_size <= df_with_ranks['rank'])  \\\n",
    "                          & (df_with_ranks['rank'] < train_size + valid_size)) \\\n",
    "      .drop('rank')\n",
    "\n",
    "    test = df_with_ranks \\\n",
    "      .filter(train_size + valid_size <= df_with_ranks['rank']) \\\n",
    "      .drop('rank')\n",
    "    \n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:46:43.491397Z",
     "start_time": "2020-02-12T00:46:43.428886Z"
    }
   },
   "outputs": [],
   "source": [
    "train, valid, test = train_val_test_split(ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:46:45.204141Z",
     "start_time": "2020-02-12T00:46:44.997635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>964</td>\n",
       "      <td>1641</td>\n",
       "      <td>5.0</td>\n",
       "      <td>898993065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>964</td>\n",
       "      <td>1704</td>\n",
       "      <td>4.0</td>\n",
       "      <td>898993065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>964</td>\n",
       "      <td>1721</td>\n",
       "      <td>3.0</td>\n",
       "      <td>898993065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0      964      1641     5.0  898993065\n",
       "1      964      1704     4.0  898993065\n",
       "2      964      1721     3.0  898993065"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "В `Test` для каждого пользователя есть `user_id, R_u`, где $R_u$ - множество фильмов, которым он поставил оценку. Для того чтобы оценить качество рассматриваемых методов будем для пользователя строить список из $N$ рекомендаций $\\hat{R}_{1\\colon N}$ и считать метрики.\n",
    "\n",
    "* $$ Precision@N = \\frac{|R_u \\cap \\hat{R}_{1\\colon N} |}{N} $$\n",
    "* $$ Recall@N = \\frac{|R_u \\cap \\hat{R}_{1\\colon N} |}{|R_u|} $$\n",
    "* $Map@N$\n",
    "\n",
    "где $N \\in \\{1,5,10\\}$\n",
    "\n",
    "https://spark.apache.org/docs/latest/mllib-evaluation-metrics.html#ranking-systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T06:23:09.475050Z",
     "start_time": "2020-02-12T06:23:09.471403Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(predicted, test, n):    \n",
    "    true_positive_counts = predicted \\\n",
    "        .join(test, on=['user_id', 'movie_id']) \\\n",
    "        .count()\n",
    "    \n",
    "    precision = true_positive_counts / (n * test.count())\n",
    "    recall = true_positive_counts / test.count()\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Results\n",
    "\n",
    "Посмотрим на результаты\n",
    "\n",
    "*Remark* скорее всего посчитать метрики для всех пользователей будет довольно долго - можно ограничится, например, случайными 10к пользователями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T06:20:43.632399Z",
     "start_time": "2020-02-12T06:20:43.630315Z"
    }
   },
   "source": [
    "**Pop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T06:22:50.437908Z",
     "start_time": "2020-02-12T06:22:50.435180Z"
    }
   },
   "outputs": [],
   "source": [
    "N = [1, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T06:25:04.012783Z",
     "start_time": "2020-02-12T06:24:59.396210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=1, precision=0.0013907668533899942, recall=0.0013907668533899942\n",
      "N=5, precision=0.0014834846436159938, recall=0.007417423218079969\n",
      "N=10, precision=0.0014216727834653275, recall=0.014216727834653274\n"
     ]
    }
   ],
   "source": [
    "for n in N:\n",
    "    pop = Popular(train, N=n)\n",
    "    \n",
    "    users_to_predict = valid \\\n",
    "                            .select('user_id') \\\n",
    "                            .distinct()\n",
    "    \n",
    "    predictions = pop.recommend(users_to_predict)\n",
    "    \n",
    "    precision, recall = calculate_metrics(predictions, valid, n)\n",
    "    \n",
    "    print(\"N={}, precision={}, recall={}\".format(n, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "431.997px",
    "width": "329.514px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "321.545px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
