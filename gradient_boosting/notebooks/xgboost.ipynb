{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#XGBoost\" data-toc-modified-id=\"XGBoost-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span><a href=\"https://xgboost.readthedocs.io/en/latest/index.html\" target=\"_blank\">XGBoost</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Baseline-Model\" data-toc-modified-id=\"Baseline-Model-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Baseline Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Prepare-Data\" data-toc-modified-id=\"Prepare-Data-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Prepare Data</a></span></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Train</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Average-Treatment-Effect\" data-toc-modified-id=\"Average-Treatment-Effect-1.1.3.1\"><span class=\"toc-item-num\">1.1.3.1&nbsp;&nbsp;</span>Average Treatment Effect</a></span></li></ul></li></ul></li><li><span><a href=\"#New-Model\" data-toc-modified-id=\"New-Model-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>New Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Prepare-Data\" data-toc-modified-id=\"Prepare-Data-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Prepare Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Categorical-Features\" data-toc-modified-id=\"Categorical-Features-1.2.1.1\"><span class=\"toc-item-num\">1.2.1.1&nbsp;&nbsp;</span>Categorical Features</a></span></li><li><span><a href=\"#Pipeline\" data-toc-modified-id=\"Pipeline-1.2.1.2\"><span class=\"toc-item-num\">1.2.1.2&nbsp;&nbsp;</span>Pipeline</a></span></li></ul></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Train</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Evaluation</a></span></li></ul></li></ul></li><li><span><a href=\"#Features-Importance\" data-toc-modified-id=\"Features-Importance-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Features Importance</a></span><ul class=\"toc-item\"><li><span><a href=\"#SHAP\" data-toc-modified-id=\"SHAP-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span><a href=\"https://github.com/slundberg/shap\" target=\"_blank\">SHAP</a></a></span></li><li><span><a href=\"#XGBoost-features-importance\" data-toc-modified-id=\"XGBoost-features-importance-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span><a href=\"https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.Booster.get_score\" target=\"_blank\">XGBoost features importance</a></a></span></li></ul></li><li><span><a href=\"#Practical-Lessons-From-Facebook\" data-toc-modified-id=\"Practical-Lessons-From-Facebook-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span><a href=\"https://quinonero.net/Publications/predicting-clicks-facebook.pdf\" target=\"_blank\">Practical Lessons From Facebook</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Prepare-Data\" data-toc-modified-id=\"Prepare-Data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Prepare Data</a></span></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Train</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Make-a-Submission\" data-toc-modified-id=\"Make-a-Submission-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Make a Submission</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжаем работать над задачей CTR-prediction с использованием датасета от Criteo.\n",
    "\n",
    "Описание задачи и данных можно посмотреть в notebook'e предыдущей практики (`sgd_logreg_nn/notebooks/ctr_prediction_mllib.ipynb`).\n",
    "\n",
    "# [XGBoost](https://xgboost.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "\n",
    "Утановим xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.0.2-py3-none-manylinux1_x86_64.whl (109.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 109.7 MB 4.5 MB/s eta 0:00:01    |███▏                            | 10.9 MB 3.3 MB/s eta 0:00:30\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/lib64/python3.5/site-packages (from xgboost) (1.3.3)\n",
      "Requirement already satisfied: numpy in /usr/lib64/python3.5/site-packages (from xgboost) (1.17.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip3.5 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "sys.path.append('./utils')\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"\"\"\n",
    "--jars xgboost4j-spark-0.72.jar,xgboost4j-0.72.jar\n",
    "--py-files sparkxgb.zip pyspark-shell\n",
    "\"\"\".replace('\\n', ' ')\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"spark_sql_examples\") \\\n",
    "    .config(\"spark.executor.memory\", \"10g\") \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .config(\"spark.task.cpus\", \"8\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "from metrics import rocauc, logloss, ne\n",
    "from processing import split_by_col\n",
    "\n",
    "from sparkxgb.xgboost import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на слудующие строки:\n",
    "\n",
    "* ```python\n",
    "sys.path.append('./utils')\n",
    "...\n",
    "from metrics import rocauc, logloss, ne\n",
    "from processing import split_by_col\n",
    "```\n",
    "\n",
    "В папке `utils` находится два файла (`metrics.py`, `processing.py`), которые содержат функции, которые нужно было реализовать в рамках предыдущей практики.\n",
    "\n",
    "\n",
    "* ```python\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"\"\"\n",
    "--jars xgboost4j-spark-0.72.jar,xgboost4j-0.72.jar\n",
    "--py-files sparkxgb.zip pyspark-shell\n",
    "\"\"\"\n",
    "...\n",
    "from sparkxgb.xgboost import *\n",
    "```\n",
    "\n",
    "Для того чтобы в рамках инфраструктуры Spark можно было использовать XGBoost, мы воспользуемся библиотекой [XGBoost4J](https://xgboost.readthedocs.io/en/latest/jvm/xgboost4j_spark_tutorial.html).\n",
    "\n",
    "В ходе выполнения занятий может быть полезно ознакомиться с исходным кодом обертки для питона, который находится в архиве `sparkxgb.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/workspace/data/criteo'\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = OrderedDict() # in python 3.6 will work with just {} because dict ordered in insertion order by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load('file:///' + TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(False, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_columns = ['_c{}'.format(i) for i in range(1, 14)]\n",
    "cat_columns = ['_c{}'.format(i) for i in range(14, 40)][:2]\n",
    "len(num_columns), len(cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0, subset=num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся пайплайном из предыдущей практики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "\n",
    "pipeline_model = PipelineModel.load(os.path.join(DATA_PATH, 'pipeline_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_c42773d6ff43,\n",
       " StringIndexer_25efb5034eb3,\n",
       " OneHotEncoderEstimator_99443336b5be,\n",
       " VectorAssembler_32b1969e093c]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1396, 545)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pipeline_model.stages[0].labels), len(pipeline_model.stages[1].labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговая размерность пространства фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1954"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = len(num_columns) + len(pipeline_model.stages[0].labels) + len(pipeline_model.stages[1].labels)\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1831957"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pipeline_model \\\n",
    "    .transform(df) \\\n",
    "    .select(F.col('_c0').alias('label'), 'features', 'id') \\\n",
    "    .cache()\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = split_by_col(df, 'id', [0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = XGBoostEstimator(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\",\n",
    "    colsample_bytree=0.9,\n",
    "    eta=0.15,\n",
    "    gamma=0.9,\n",
    "    max_depth=8,\n",
    "    min_child_weight=50.0,\n",
    "    subsample=0.9,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss', \n",
    "    silent=0,\n",
    "    num_round=20,\n",
    "    nthread=2,\n",
    "    nworkers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45 ms, sys: 13.7 ms, total: 58.7 ms\n",
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = estimator.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем [booster](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.Booster) обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._call_java(\"booster\").saveModel(os.path.join(DATA_PATH, 'xgb.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_metrics = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Treatment Effect\n",
    "\n",
    "Пусть даны две экспериментальные группы treatment ($T$) и control ($C$), где\n",
    "\n",
    "* `treatment` - группа с изменением (например, новая модель)\n",
    "* `control` - группа без изменений\n",
    "\n",
    "Рассмотрим метрику $X$, значение которой мы расчитали для наших групп ($X_T, X_C$).\n",
    "\n",
    "Тогда под ATE будем иметь в виду\n",
    "$$ \\Delta\\% = \\frac{X_T - X_C}{X_C} \\cdot 100 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ate(groups, control_name) -> pd.DataFrame:\n",
    "    \"\"\"Get Average Treatment Effect\n",
    "    groups - dictionary where keys - names of models, values - dicts of pairs <metric_name>, <metric_value>\n",
    "    control_name - name of baseline model\n",
    "    \n",
    "    return pd.DataFrame (rows corresponds to metrics, cols corresponds to models and ATE with respect to control)\n",
    "    \"\"\"\n",
    "    metrics = pd.DataFrame.from_records(groups, columns=groups.keys())\n",
    "    metrics.index.name = 'metric'\n",
    "    return metrics.subtract(metrics['xgb_baseline'], axis='index') * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72939774500193"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocauc(model, val_df, probabilities_col='probabilities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7281438220858357"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_metrics['ROC AUC'] = rocauc(model, test_df, probabilities_col='probabilities')\n",
    "baseline_metrics['ROC AUC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics['xgb_baseline'] = baseline_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним результаты с логрег моделью из предыдущей практики.\n",
    "\n",
    "1. Загрузить обученную `LogReg` модель\n",
    "2. Посчитать метрики на `test_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "logreg_path = os.path.join(DATA_PATH, 'logreg_baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel: uid = LogisticRegression_9229974147cc, numClasses = 2, numFeatures = 1954"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = LogisticRegressionModel.load(logreg_path)\n",
    "lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "logrec_metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6999639315838824"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logrec_metrics['ROC AUC'] = rocauc(lr_model, test_df, probabilities_col='probability')\n",
    "logrec_metrics['ROC AUC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics['logreg'] = logrec_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построить таблицу ATE используя метод `get_ate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgb_baseline</th>\n",
       "      <th>logreg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROC AUC</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.817989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         xgb_baseline    logreg\n",
       "metric                         \n",
       "ROC AUC           0.0 -2.817989"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ate(all_metrics, 'xgb_baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Model\n",
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load('file:///' + TRAIN_PATH)\n",
    "\n",
    "df = df.sample(False, 0.5)\n",
    "df = df.fillna(0, subset=num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>_c1</th>\n",
       "      <th>_c2</th>\n",
       "      <th>_c3</th>\n",
       "      <th>_c4</th>\n",
       "      <th>_c5</th>\n",
       "      <th>_c6</th>\n",
       "      <th>_c7</th>\n",
       "      <th>_c8</th>\n",
       "      <th>_c9</th>\n",
       "      <th>...</th>\n",
       "      <th>_c31</th>\n",
       "      <th>_c32</th>\n",
       "      <th>_c33</th>\n",
       "      <th>_c34</th>\n",
       "      <th>_c35</th>\n",
       "      <th>_c36</th>\n",
       "      <th>_c37</th>\n",
       "      <th>_c38</th>\n",
       "      <th>_c39</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1465</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>e5f8f18f</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>f3ddd519</td>\n",
       "      <td>None</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>b34f3128</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>319</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>40</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>bbf70d82</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>16e2e3b3</td>\n",
       "      <td>None</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>d859b4dd</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _c0  _c1  _c2  _c3  _c4   _c5  _c6  _c7  _c8  _c9  ...      _c31  _c32  \\\n",
       "0    1    0   -1    0    0  1465    0   17    0    4  ...  e5f8f18f  None   \n",
       "1    1   88  319    0    4     5    4   89   40   88  ...  bbf70d82  None   \n",
       "\n",
       "   _c33      _c34  _c35      _c36      _c37  _c38  _c39  id  \n",
       "0  None  f3ddd519  None  32c7478e  b34f3128  None  None  12  \n",
       "1  None  16e2e3b3  None  32c7478e  d859b4dd  None  None  41  \n",
       "\n",
       "[2 rows x 41 columns]"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Features\n",
    "\n",
    "See [Doc](https://spark.apache.org/docs/latest/ml-pipeline.html) for additional details on Transformers and Encoders.\n",
    "\n",
    "Implement classes below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.ml.param import Params\n",
    "from pyspark import keyword_only  \n",
    "\n",
    "# Fitted Model\n",
    "class MeanTargetEncoderModel(pyspark.ml.Model, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    params_names = ['inputCol', 'featuresCol', 'prior', 'mean_target']\n",
    "    \n",
    "    @keyword_only\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()      \n",
    "        for param_name in self.params_names:\n",
    "            # dynamic python is so brilliant\n",
    "            setattr(self, param_name, Param(self, param_name, ''))\n",
    "        self._set(**kwargs)\n",
    "        \n",
    "    def get(self, param):\n",
    "        assert param in self.params_names, \"Parameter {} not defined\".format(param)\n",
    "        return self.getOrDefault(getattr(self, param))\n",
    "    \n",
    "    def transform(self, df):\n",
    "        mean_target_df = sqlContext.createDataFrame(pd.DataFrame.from_dict(self.get('mean_target'))) # due to serialization\n",
    "        return df \\\n",
    "            .join(mean_target_df, self.get('inputCol'), how='left') \\\n",
    "            .fillna(self.get('prior'), subset=self.get('featuresCol'))\n",
    "\n",
    "\n",
    "# Estimator\n",
    "class MeanTargetEncoder(pyspark.ml.Estimator):    \n",
    "    def __init__(self, inputCol, targetCol, featuresCol, alpha=1.):\n",
    "        super().__init__()\n",
    "        self.inputCol = inputCol\n",
    "        self.targetCol = targetCol\n",
    "        self.featuresCol = featuresCol\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def fit(self, df):\n",
    "        prior = df.select(F.mean(self.targetCol)).first()[0]\n",
    "        \n",
    "        mean_target = df \\\n",
    "            .groupby(self.inputCol) \\\n",
    "            .agg(F.sum(self.targetCol).alias('sum_target'), F.count(self.inputCol).alias('total_target')) \\\n",
    "            .withColumn(self.featuresCol, \n",
    "                        (F.col('sum_target') + self.alpha * prior) / (F.col('total_target') + self.alpha)) \\\n",
    "            .select(self.inputCol, self.featuresCol).toPandas().to_dict()\n",
    "        \n",
    "        return MeanTargetEncoderModel(inputCol=self.inputCol, featuresCol=self.featuresCol, \\\n",
    "                                      prior=prior, mean_target=mean_target)\n",
    "    \n",
    "    \n",
    "    def transform_train(self, df):\n",
    "        # should return sliding window MTE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "\n",
    "cat_enc_columns = [cat_col + '_enc' for cat_col in cat_columns]\n",
    "\n",
    "mean_target_encoders = [MeanTargetEncoder(cat_col, '_c0', cat_enc_col) \n",
    "                        for cat_col, cat_enc_col in zip(cat_columns, cat_enc_columns)]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=num_columns + cat_enc_columns, outputCol=\"features\").setHandleInvalid(\"keep\")\n",
    "\n",
    "pipeline = Pipeline(stages=mean_target_encoders + [assembler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "mte_pipeline_path = os.path.join(DATA_PATH, 'mte_pipeline_model')\n",
    "if os.path.isdir(mte_model_path):\n",
    "    shutil.rmtree(mte_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model.save(mte_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "\n",
    "pipeline_model = PipelineModel.load(mte_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1833588"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pipeline_model \\\n",
    "    .transform(df) \\\n",
    "    .select(F.col('_c0').alias('label'), 'features', 'id') \\\n",
    "    .cache()\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = split_by_col(df, 'id', [0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "Train XGBoost on the new set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.6 ms, sys: 22.8 ms, total: 76.4 ms\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = estimator.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._call_java(\"booster\").saveModel(os.path.join(DATA_PATH, 'xgb_mte.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7366392438946137"
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocauc(model, val_df, probabilities_col='probabilities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнить результаты новой модели с `xgb_baseline` и `log_reg` с помощью функции `get_ate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_mte_metrics = {\n",
    "    'ROC AUC': rocauc(model, test_df, probabilities_col='probabilities')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics['xgb_mte'] = xgb_mte_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgb_baseline</th>\n",
       "      <th>logreg</th>\n",
       "      <th>xgb_mte</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ROC AUC</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.817989</td>\n",
       "      <td>0.745053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         xgb_baseline    logreg   xgb_mte\n",
       "metric                                   \n",
       "ROC AUC           0.0 -2.817989  0.745053"
      ]
     },
     "execution_count": 851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ate(all_metrics, 'xgb_baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Importance\n",
    "\n",
    "## [SHAP](https://github.com/slundberg/shap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3.5 install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import xgboost as xgb\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "bst = xgb.Booster()\n",
    "bst.load_model(os.path.join(DATA_PATH, 'xgb.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имея `booster` модели можно, например, посмотреть на то какие деревья получились в итоге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(bst.get_dump()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df.sample(False, 0.05)\n",
    "sample_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "def df_to_csr(df, dim):\n",
    "    data = []\n",
    "    row_ind = []\n",
    "    col_ind = []\n",
    "    \n",
    "    sparse_vecs = df.rdd.map(lambda row: row.features).collect()\n",
    "    for i, vec in enumerate(sparse_vecs):\n",
    "        for idx, val in zip(vec.indices, vec.values):\n",
    "            data.append(val)\n",
    "            row_ind.append(i)\n",
    "            col_ind.append(idx)\n",
    "        \n",
    "    return csr_matrix((data, (row_ind, col_ind)), shape=(len(sparse_vecs), dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = df_to_csr(sample_df, dim)\n",
    "dtest = xgb.DMatrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_arr = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "explainer = shap.TreeExplainer(bst)\n",
    "shap_values = explainer.shap_values(dtest, tree_limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_arr, max_display=20, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [XGBoost features importance](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.Booster.get_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_score(booster, importance):\n",
    "    gains_xgb = booster.get_score(importance_type=importance)\n",
    "    gains = {}\n",
    "    for f, g in gains_xgb.items():\n",
    "        gains[f] = g\n",
    "    sorted_gains = sorted(list(gains.items()), key=lambda x: -x[1])\n",
    "    return sorted_gains\n",
    "\n",
    "\n",
    "features_scores = get_feature_score(bst, 'gain')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "f_names, f_scores = zip(*features_scores)\n",
    "features_scores_pdf = pd.DataFrame({'feature': f_names, 'gain': f_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "_, ax = plt.subplots(figsize=(8,8))\n",
    "ax = sns.barplot(x='gain', y='feature', data=features_scores_pdf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Practical Lessons From Facebook](https://quinonero.net/Publications/predicting-clicks-facebook.pdf)\n",
    "\n",
    "## Prepare Data\n",
    "\n",
    "* Реализуйте модель из статьи (LogReg поверх XGBoost)\n",
    "\n",
    "* Попробуйте реализовать Negatives Subsampling + Re-calibration описанный в статье (доп. баллы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "######### YOUR CODE HERE #############\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "######### YOUR CODE HERE #############\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration(model, df):\n",
    "    ######################################\n",
    "    ######### YOUR CODE HERE #############\n",
    "    ######################################\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните новую модель со всеми предыдущими с помощью `get_ate`. При сравнении использовать еще и метрику calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "######### YOUR CODE HERE #############\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission\n",
    "\n",
    "Если в результате работы получилась модель, которая лучше чем ЛогРег из предыдущей практики, то точно нужно сделать submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
